# About

Unlike a traditional ROS package, a webapp is usually deployed along with many other components. Here is an example of how a web deployment might looks like
![](https://www.fullstackpython.com/img/visuals/full-stack-python-map.png)
Credits: https://www.fullstackpython.com

`rmf-web` only provides the application, as you can see in the diagram, a full web deployment consists of many, many other components. There is no single way to "run" `rmf-web` as you would normally expect from a desktop application. Each deployment will be different, depending on the environment that you are running, the licenses you can use, the SaaS that you are using, the cloud infrastructure (or lack of) and many other factors, the application itself is only one of the component among the sea of many software used in a modern webapp deployment.

Deploying a web app can be very complicated, so this repo serves as an example deployment of `rmf-web` that can be used as a starting point for a full deployment. In this example deployment, we will not be using any SaaS and public cloud infrastructure, all products used are open source and can be deployed on-premise. The goal is to present a solution that can be deployed in an airgapped network.

# Software Stack

In this example, we will be using the following software

rmf-web:
* rmf-server (aka api-server)
* dashboard

others:
* kubernetes
* minikube
* keycloak
* nginx
* postgres
* minio
* fluentd

**NOTE: If you are using this example as a starting point for your own deployment, you must make sure that you have the proper license to use the softwares used in this example.**

# Setting Up

## RMF

`rmf-web` needs RMF to provide it's functions, while you could technically deploy `rmf-web` without RMF, doing that would not be useful and you wouldn't be able to do anything with it.

For this example we will be using [rmf_demos](https://github.com/open-rmf/rmf_demos) as a local "deployment" of RMF, check that you have a working installation with

```bash
ros2 launch rmf_demos office.launch.xml
```

## kubernetes

To start things off, we need an infrastructure to management our deployment. These days there are many public cloud services available, including new "serverless" architecture, but in this example, since we would like to be able to deploy in an airgapped network, all the public infrastructures are out.

kubernetes has the advantage that it is very popular and there are several open source projets that allow you to quickly create your own cluster. In this example, we will be using `minikube` to create our own cluster.

```bash
./start-minikube.sh
```

This will download `minikube` to `.bin/minikube` and start a cluster.

To stop the minikube cluster, run

```bash
.bin/minikube stop
```

## DNS

In a real deployment, you would buy a domain and configure your dns provider to point it to your public ip. For this example, we will be deploying to `example.com`, but since we don't actually own the domain we will be using the `/etc/hosts` file to resolve it to our minikube ip.

```bash
if grep -q 'example.com' /etc/hosts; then
  sudo sed "s/.*example.com.*/$(.bin/minikube ip) example.com/" /etc/hosts -i
else
  echo "$(.bin/minikube ip) example.com" | sudo tee -a /etc/hosts
fi
```

This will create an entry in `/etc/hosts` to point `example.com` to the minikube cluster.

Check that it works by pinging it

```bash
ping example.com
```

## SSL Certificate

In a real deployment, you will get a verified cert, for this example, we will be using the default certs generated by minikube and keycloak. These are self-signed cert so you will get security warnings from the browser when you visit the urls, for the purpose of this example, you will need to proceed with the security exception.

# Deploying rmf-web

## Keycloak

### Deploying

In this example, we will be using [Keycloak](https://www.keycloak.org/) to do user management and authentication. It is an open source identity and access management, released under the Apache 2.0 license.

There is a kubernetes resource file to deploy keycloak along with postgres for its database.

```bash
.bin/minikube kubectl -- apply -f k8s/keycloak.yaml
```

This requires internet connection, see [Deploying in an airgapped network](#deploying-in-an-airgapped-network) if you are in an airgap network. tldr:

### connected to internet

```bash
docker pull quay.io/keycloak/keycloak:12.0.4
```

### connected to airgap network

build the image

``` bash
docker build -t rmf-web/keycloak -f docker/keycloak/keycloak.dockerfile docker/keycloak/
```

"publish" the image

``` bash
docker save rmf-web/keycloak | bash -c 'eval $(.bin/minikube docker-env) && docker load'
```

```
.bin/minikube kubectl -- apply -f k8s/keycloak.yaml
```

Use kubectl to wait for keycloak to be ready

```bash
.bin/minikube kubectl -- get deployment
```

When it's ready, you should see something like

```
NAME          READY   UP-TO-DATE   AVAILABLE   AGE
keycloak      1/1     1            1           55s
keycloak-db   1/1     1            1           56s
```

When keycloak is ready, test it out by going to https://example.com/auth. The superuser created by this deployment is `user=admin,password=admin`.

### Configuration

For this example, we will

1. Create a `rmf-web` realm.
1. Create a `dashboard` and `reporting` client.
1. Add https://example.com to the list of allowed origins.
1. Create an example user with user=example password=example.

For brevity, you can use the provided script to automate the process.

```bash
node keycloak-tools/bootstrap-keycloak.js
```

You may check out the keycloak docs if you would like to learn more about it's features.

### Get the keycloak cert

Keycloak implements the openid-connect standard, by default the JWT is signed with an auto generated RSA key. We will need the cert so that `rmf-web` backend services can verify the token. You can use the admin console to get it or use the provided script

```bash
node keycloak-tools/get-cert.js > keycloak.pem
```

If you wish to, you may check the cert with

```bash
openssl x509 -in keycloak.pem -noout -text
```

get the public key from the cert

```bash
openssl x509 -in keycloak.pem -pubkey -noout -out jwt-pub-key.pub
```

**NOTE: deleting the persistent volume used by postgres will delete the database, the next time you start keycloak it will start from a fresh state, meaning the realm we created will be gone and the public key will be different.**

### Add the cert to kubernetes

In order to use the cert, we will add it as a configmap to kubernetes

```bash
kubectl create configmap jwt-pub-key --from-file=jwt-pub-key.pub -o=yaml --dry-run=client | kubectl apply -f -

```

## rmf-server

### Build minimal RMF image

We will need a minimal base image containing all the RMF messages. This image will be used to build the rmf-server image.

How you get this image will vary depending what version of RMF, and what extensions you are deploying it with. It is important that rmf-server is using the exact same message definitions as used by the deployment of RMF. For this example, we assume that you built rmf_demos from source using the main branch, so we will build the messages from source as well.

Get RMF source code

```bash
mkdir -p ws/rmf
pushd ws/rmf
wget https://raw.githubusercontent.com/open-rmf/rmf/main/rmf.repos
mkdir -p src
vcs import src < rmf.repos
popd
```

build the image

```bash
docker build -t rmf-web/builder -f docker/builder.dockerfile ws/rmf/src
```

NOTE: It is not recommended to use the default "latest" tag in a real deployment, be sure to tag your images accordingly.

### Build rmf-server image

Get rmf-web source

```bash
git clone --depth 1 https://github.com/open-rmf/rmf-web ws/rmf-web
```

build the image

```bash
docker build -t rmf-web/rmf-server -f docker/rmf-server.dockerfile ws/rmf-web
```

"publish" the image, in a normal deployment, you would publish this to your docker registry, since we don't have a registry in this example, we will push the image directly to minikube

```bash
docker save rmf-web/rmf-server | bash -c 'eval $(.bin/minikube docker-env) && docker load'
```

create a configmap for the server

```bash
kubectl create configmap rmf-server-config --from-file=rmf_server_config.py -o=yaml --dry-run=client | kubectl apply -f -
```

deploy it

```bash
.bin/minikube kubectl -- apply -f k8s/rmf-server.yaml
```

## dashboard

build the image

```bash
docker build -t rmf-web/dashboard -f docker/dashboard.dockerfile ws/rmf-web
```

"publish" the image

```bash
docker save rmf-web/dashboard | bash -c 'eval $(.bin/minikube docker-env) && docker load'
```

deploy it

```bash
.bin/minikube kubectl -- apply -f k8s/dashboard.yaml
```

## [MinIO](https://github.com/minio/minio)
MinIO is a High-Performance Object Storage released under Apache License v2.0. MinIO has several uses but in our case, we will use MinIO to store logs.

This requires internet connection, see [Deploying in an airgapped network](#deploying-in-an-airgapped-network) if you are in an airgap network.

Let's deploy our `Minio`:

``` bash
.bin/minikube kubectl -- apply -f k8s/minio.yaml
```

## FluentD

Fluentd is an open source data collector for unified logging layer. Fluentd allows you to unify data collection and consumption for a better use and understanding of data.

### Fluentd Configmap

We have 4 files in our `fluentd-configmap.yaml` :
* `fluent.conf`: Our main config which includes all configurations we want to run.
* `pods-fluent.conf`: `tail` config that sources all pod logs on the `kubernetes` host in the cluster.
* `minio-fluent.conf`: `match` config to capture all logs and send them to MinIO. Every chunck of logs should have 5mb.
Capture all logs and send them to MinIO. Every chunck of logs should have 5mb.
* `minio-fluent-dev.conf`: `match` config to capture all logs and send them to MinIO. Every chunck of logs should have 2kb for development purposes.

Let's deploy our `configmap`:

``` bash
.bin/minikube kubectl -- apply -f k8s/fluentd-configmap.yaml
```

### Fluentd Daemonset

Let's deploy the `daemonset`,

This requires internet connection, see [Deploying in an airgapped network](#deploying-in-an-airgapped-network) if you are in an airgap network.

``` bash
.bin/minikube kubectl -- apply -f k8s/fluentd.yaml
```

### Build reporting-server image

build the image

```bash
docker build -t rmf-web/reporting-server -f docker/reporting-server.dockerfile ws/rmf-web
```

"publish" the image, in a normal deployment, you would publish this to your docker registry, since we don't have a registry in this example, we will push the image directly to minikube

```bash
docker save rmf-web/reporting-server | bash -c 'eval $(.bin/minikube docker-env) && docker load'
```

create a configmap for the server

```bash
kubectl create configmap reporting-server-config --from-file=reporting_server_config.py -o=yaml --dry-run=client | kubectl apply -f -
```

deploy it

```bash
.bin/minikube kubectl -- apply -f k8s/reporting-server.yaml
```

### Build reporting-server-migrations image

To update our reporting-server DB we will create a container with the migrations. We can build the image by running

```bash
docker build -t rmf-web/reporting-server-migrations -f docker/reporting-server-migrations.dockerfile ws/rmf-web
```

"publish" the image, in a normal deployment, you would publish this to your docker registry, since we don't have a registry in this example, we will push the image directly to minikube

```bash
docker save rmf-web/reporting-server-migrations | bash -c 'eval $(.bin/minikube docker-env) && docker load'
```

### Run migration job

Once the `reporting-server` is deployed and we have the migrations, we can run the migration job. We can do that by running:

```bash
.bin/minikube kubectl -- apply -f k8s/jobs/reporting-server-migrations-job.yaml
```

## Reporting

build the image

```bash
docker build -t rmf-web/reporting -f docker/reporting.dockerfile ws/rmf-web
```

"publish" the image

```bash
docker save rmf-web/reporting | bash -c 'eval $(.bin/minikube docker-env) && docker load'
```

deploy it

```bash
.bin/minikube kubectl -- apply -f k8s/reporting.yaml
```

## CronJobs

Cronjobs are jobs that run periodically on a given schedule. You can configure the schedule following this [cron schedule syntax](https://kubernetes.io/docs/concepts/workloads/controllers/cron-jobs/#cron-schedule-syntax)

deploy cronjobs

```bash
.bin/minikube kubectl -- apply -f k8s/jobs/cronjobs.yaml
```

## Test the deployment

If not done so already, launch the office demo

```bash
ros2 launch rmf_demos office.launch.xml headless:=true
```

Go to https://example.com/dashboard, if everything works, you should see a log in screen, use user=example, password=example.

After that, you should be presented with the dashboard, you have successfully deployed `rmf-web`! 🎉

## Automating deployment

It can be very useful to automate everything mentioned above and instantly deploy rmf-web. The `deploy.sh` script is an example of how you can do that.

Before you run the script, first you have to obtain the source. Refer to the above instructions if you don't know how to do it. You should have a git repo for rmf-web and a colcon workspace for rmf, then just run

```bash
./deploy.sh --rmf-ws <path-to-rmf-ws> --rmf-web-ws <path-to-rmf-web-ws>
```

Note: If you followed the above instructions to obtain the source, your rmf workspace will be in `ws/rmf`, and your rmf-web workspace will be in `ws/rmf-web`. So you will run it with `./deploy.sh --rmf-ws ws/rmf --rmf-web-ws ws/rmf`.

Sit back and relax, everything will be done for you!

# Troubleshooting

## Deploying in an airgapped network

There are certain parts that requires an internet connection to fetch the docker images and source codes, in order to deploy from within an airgapped network, you can use obtain the images first, then push them directly to minikube. For example

when you have internet, run this to get the keycloak, MinIO and Fluentd images
```bash
docker pull quay.io/keycloak/keycloak:12.0.4
docker pull minio/minio:RELEASE.2021-03-10T05-11-33Z
docker pull fluent/fluentd-kubernetes-daemonset:v1.12.2-debian-s3-1.0
```

now, connect to the airgapped network and push the images to minikube
```bash
docker save quay.io/keycloak/keycloak:12.0.4 | bash -c 'eval $(.bin/minikube docker-env) && docker load'
docker save minio/minio:RELEASE.2021-03-10T05-11-33Z | bash -c 'eval $(.bin/minikube docker-env) && docker load'
docker save fluent/fluentd-kubernetes-daemonset:v1.12.2-debian-s3-1.0 | bash -c 'eval $(.bin/minikube docker-env) && docker load'
```

now you can deploy keycloak, MinIO and Fluentd without require access to the internet

If connection to the internet from the same PC is not possible, you can use `docker save` to save the image into a tarball, then transfer it to the minikube PC through whatever method possible (thumbdrives, cds etc) and use `docker load` to load the image. Then you can use `.bin/minikube load` to push it into minikube.


## Updating the deployment

If you make changes to the images, you will need to publish the new image and update the kubernetes resources.
Since we are pushing the images directly to minikube, we can't tell kubernetes to pull the new image as our image doesn't actually exist in the registry. In order to tell kubernetes to use the new image, you need to delete the current deployment and re-deploy again.

```bash
.bin/minikube kubectl -- delete -f <path-to-k8s-file>
```

Note that when using the above method to delete the keycloak deployment, it will delete the persistent volume containing the database as well, to only delete the keycloak app, use

```bash
.bin/minikube kubectl -- delete -f k8s/keycloak.yaml -ltier=app
```

push the image to minikube

```bash
docker save <image> | bash -c 'eval $(.bin/minikube docker-env) && docker load'
# optional, delete old images
docker system prune
```

re-deploy it

```bash
.bin/minikube kubectl -- apply -f <path>
```

## Get a shell into the container

It can be very useful to get a shell into the pod, kubernetes allow you to do this easily.

```bash
.bin/minikube kubectl -- get pods
.bin/minikube kubectl -- exec -it <pod> -- bash
```

## I got a blank white page

The most common cause is that connection to the keycloak server is not working, see if you can open the keycloak ui at https://example.com/auth.

## It is stuck in "downloading building map..."

This is usually because the rmf-server server can't connect to rmf, first make sure that

* rmf_demos is running
* your version of rmf_demos is exactly the same as the one used to build your rmf-server image.

If it still doesn't work, get a shell into the rmf-server port

```bash
.bin/minikube kubectl -- exec -it deployment/rmf-server -- bash
```

When inside, test that you can connect to rmf

```bash
. /opt/rmf/setup.bash
ros2 service call get_building_map building_map_msgs/srv/GetBuildingMap '{}'
```

If you can't connect to rmf with ros cli tools, that indicates that there is something wrong with the network setup. Make sure there are no firewalls or other things blocking the traffic.

If you can connect to rmf, there is a chance that there is some discovery issues with rclnodejs. One possible workaround is to restart it. Exit your session inside the container and back on the host,

```bash
.bin/minikube kubectl -- delete -f k8s/rmf-server.yaml
.bin/minikube kubectl -- apply -f k8s/rmf-server.yaml
```
